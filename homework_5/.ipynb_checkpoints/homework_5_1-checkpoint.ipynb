{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "defee111",
   "metadata": {},
   "source": [
    "№1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78d97ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyconll in c:\\users\\pavel_nazarenko\\anaconda3\\lib\\site-packages (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28031e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.tag import DefaultTagger\n",
    "from nltk.tag import UnigramTagger, BigramTagger, TrigramTagger\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import corus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyconll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a610935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru_taiga-ud-train (1).conllu\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-train.conllu'\n",
    "train = wget.download(url)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "046088c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru_taiga-ud-dev (1).conllu\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "url = 'https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-Taiga/master/ru_taiga-ud-dev.conllu'\n",
    "test = wget.download(url)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ea908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Общая обучающая выборка\n",
    "full_train = pyconll.load_from_file('ru_taiga-ud-train.conllu')\n",
    "full_test = pyconll.load_from_file('ru_taiga-ud-dev.conllu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21fb62ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata_train = []\n",
    "for sent in full_train[:]:\n",
    "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
    "    \n",
    "fdata_sent_test = []\n",
    "for sent in full_test[:]:\n",
    "    fdata_sent_test.append([token.form for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ff827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparing_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5461413f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24167987321711568"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "default_tagger = DefaultTagger('NOUN')\n",
    "\n",
    "# display(default_tagger.tag(fdata_sent_test[100]))\n",
    "display(default_tagger.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('default_tagger', default_tagger.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aaeaf7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6831418383518225"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 240 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "unigram_tagger = UnigramTagger(fdata_train)\n",
    "\n",
    "# display(unigram_tagger.tag(fdata_sent_test[100]))\n",
    "display(unigram_tagger.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('unigram_tagger', unigram_tagger.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3138150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6859152139461173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 361 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
    "\n",
    "# display(bigram_tagger.tag(fdata_sent_test[100]))\n",
    "display(bigram_tagger.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('bigram_tagger', bigram_tagger.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7377c5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6867076069730587"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 484 ms\n",
      "Wall time: 478 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
    "\n",
    "# display(trigram_tagger.tag(fdata_sent_test[100]))\n",
    "display(trigram_tagger.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('trigram_tagger', trigram_tagger.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8b2561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import TrigramTagger \n",
    "\n",
    "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
    "    for cls in tagger_classes:\n",
    "        backoff = cls(train_sents, backoff=backoff)\n",
    "    return backoff\n",
    "\n",
    "backoff = DefaultTagger('NOUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d3959a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.785756735340729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.19 s\n",
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tag = backoff_tagger(fdata_train,  \n",
    "                     [UnigramTagger, BigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "display(tag.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('U_B_T', tag.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf0629e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7847662440570523"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 609 ms\n",
      "Wall time: 613 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tag = backoff_tagger(fdata_train,  \n",
    "                     [UnigramTagger, BigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "display(tag.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('U_B', tag.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6194ed4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.713648969889065"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1 s\n",
      "Wall time: 998 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tag = backoff_tagger(fdata_train,  \n",
    "                     [BigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "display(tag.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('B_T', tag.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3fdf14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7859548335974643"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 625 ms\n",
      "Wall time: 621 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tag = backoff_tagger(fdata_train,  \n",
    "                     [UnigramTagger, TrigramTagger],  \n",
    "                     backoff = backoff) \n",
    "  \n",
    "display(tag.evaluate(fdata_test))\n",
    "\n",
    "comparing_list.append(('U_T', tag.evaluate(fdata_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b152028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = []\n",
    "train_label = []\n",
    "for sent in fdata_train[:]:\n",
    "    for tok in sent:\n",
    "        if (tok[0] is None) or (tok[1] is None):\n",
    "            continue\n",
    "        train_tok.append(tok[0])\n",
    "        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n",
    "        \n",
    "test_tok = []\n",
    "test_label = []\n",
    "for sent in fdata_test[:]:\n",
    "    for tok in sent:\n",
    "        if (tok[0] is None) or (tok[1] is None):\n",
    "            continue\n",
    "        test_tok.append(tok[0])\n",
    "        test_label.append('NO_TAG' if tok[1] is None else tok[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13018b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e1f2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_enc_labels = le.transform(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30560050",
   "metadata": {},
   "source": [
    "COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fc8e950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7794175911251982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cvtr = CountVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "\n",
    "X_train = cvtr.fit_transform(train_tok)\n",
    "X_test = cvtr.transform(test_tok)\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=8, max_iter=20)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "display(accuracy_score(test_enc_labels, pred))\n",
    "\n",
    "comparing_list.append(('count_vectorizer', accuracy_score(test_enc_labels, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03edc7",
   "metadata": {},
   "source": [
    "HASHING VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa20562a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5879556259904913"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hvtr = HashingVectorizer(ngram_range=(1, 3), analyzer='char', n_features=100)\n",
    "\n",
    "X_train = hvtr.fit_transform(train_tok)\n",
    "X_test = hvtr.transform(test_tok)\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=8, max_iter=20)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "display(accuracy_score(test_enc_labels, pred))\n",
    "\n",
    "comparing_list.append(('hashing_vectorizer', accuracy_score(test_enc_labels, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d14bba",
   "metadata": {},
   "source": [
    "TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "111ee22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7106774960380349"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfvtr = TfidfVectorizer(ngram_range=(1, 3), analyzer='char')\n",
    "\n",
    "X_train = tfvtr.fit_transform(train_tok)\n",
    "X_test = tfvtr.transform(test_tok)\n",
    "\n",
    "lr = LogisticRegression(random_state=0, n_jobs=8, max_iter=20)\n",
    "lr.fit(X_train, train_enc_labels)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "display(accuracy_score(test_enc_labels, pred))\n",
    "\n",
    "comparing_list.append(('tfidf_vectorizer', accuracy_score(test_enc_labels, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45cc40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('default_tagger', 0.24167987321711568),\n",
       " ('unigram_tagger', 0.6831418383518225),\n",
       " ('bigram_tagger', 0.6859152139461173),\n",
       " ('trigram_tagger', 0.6867076069730587),\n",
       " ('U_B_T', 0.785756735340729),\n",
       " ('U_B', 0.7847662440570523),\n",
       " ('B_T', 0.713648969889065),\n",
       " ('U_T', 0.7859548335974643),\n",
       " ('count_vectorizer', 0.7794175911251982),\n",
       " ('hashing_vectorizer', 0.5879556259904913),\n",
       " ('tfidf_vectorizer', 0.7106774960380349)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d61cea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagger</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U_T</td>\n",
       "      <td>0.785955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U_B_T</td>\n",
       "      <td>0.785757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U_B</td>\n",
       "      <td>0.784766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>count_vectorizer</td>\n",
       "      <td>0.779418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B_T</td>\n",
       "      <td>0.713649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tfidf_vectorizer</td>\n",
       "      <td>0.710677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trigram_tagger</td>\n",
       "      <td>0.686708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bigram_tagger</td>\n",
       "      <td>0.685915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unigram_tagger</td>\n",
       "      <td>0.683142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hashing_vectorizer</td>\n",
       "      <td>0.587956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default_tagger</td>\n",
       "      <td>0.241680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tagger  accuracy\n",
       "7                  U_T  0.785955\n",
       "4                U_B_T  0.785757\n",
       "5                  U_B  0.784766\n",
       "8     count_vectorizer  0.779418\n",
       "6                  B_T  0.713649\n",
       "10    tfidf_vectorizer  0.710677\n",
       "3       trigram_tagger  0.686708\n",
       "2        bigram_tagger  0.685915\n",
       "1       unigram_tagger  0.683142\n",
       "9   hashing_vectorizer  0.587956\n",
       "0       default_tagger  0.241680"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(comparing_list, columns=['tagger', 'accuracy']).sort_values(by='accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
